# Hypothesis Testing

## Introduction

Hypothesis testing is a fundamental statistical approach used to make inferences about populations based on sample data. In ecological and forestry research, hypothesis testing helps researchers determine whether observed patterns or differences are statistically significant or merely due to random chance.

## The Logic of Hypothesis Testing

### Null and Alternative Hypotheses

The foundation of hypothesis testing involves two competing hypotheses:

1. **Null Hypothesis (H₀)**: This is the default position that assumes no effect, no difference, or no relationship exists. For example, "There is no difference in tree height between two forest types."

2. **Alternative Hypothesis (H₁ or Hₐ)**: This is the hypothesis that the researcher typically wants to provide evidence for. For example, "There is a significant difference in tree height between two forest types."

### Example in Ecological Research

Let's consider a specific example from forestry research:

- **Research Question**: Is there a difference in the average height of oak trees between Site A and Site B?
- **Null Hypothesis (H₀)**: There is no difference in the average height of oak trees between Site A and Site B.
- **Alternative Hypothesis (H₁)**: There is a significant difference in the average height of oak trees between Site A and Site B.

## Understanding P-values and Significance Levels

### The P-value

The p-value is the probability of obtaining results at least as extreme as those observed, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis.

### Significance Level (Alpha)

The significance level, often denoted as α (alpha), represents the threshold for statistical significance. In most research, it is set at 0.05 (5%). This value signifies the maximum acceptable probability of making a Type I error — wrongly rejecting the null hypothesis when it is true.

## Example: Two-Sample t-test

```{r}
# Simulate tree height data for two sites
set.seed(123)
site_A <- rnorm(30, mean = 25, sd = 5)  # 30 trees with mean height 25m
site_B <- rnorm(30, mean = 28, sd = 5)  # 30 trees with mean height 28m

# Create a data frame
tree_data <- data.frame(
  height = c(site_A, site_B),
  site = factor(rep(c("A", "B"), each = 30))
)

# Visualize the data
library(ggplot2)
ggplot(tree_data, aes(x = site, y = height, fill = site)) +
  geom_boxplot() +
  labs(title = "Tree Heights by Site",
       x = "Site",
       y = "Height (m)") +
  theme_minimal()

# Perform a t-test
t_test_result <- t.test(height ~ site, data = tree_data)
print(t_test_result)

# Interpret the result
alpha <- 0.05
if (t_test_result$p.value < alpha) {
  cat("With a p-value of", round(t_test_result$p.value, 4), 
      "we reject the null hypothesis.\n",
      "There is a statistically significant difference in tree heights between sites.")
} else {
  cat("With a p-value of", round(t_test_result$p.value, 4), 
      "we fail to reject the null hypothesis.\n",
      "There is not enough evidence to conclude a significant difference in tree heights.")
}
```

## Example: Using Marine Dataset for Two-Sample t-test

Let's apply the t-test to analyze real data. We'll use our marine dataset to compare fishing yields between different regions:

```{r}
# Load necessary packages
library(tidyverse)

# Load the marine dataset
marine_data <- read_csv("../data/marine/ocean_data.csv")

# View the structure of the dataset
str(marine_data)

# Let's compare fishing yields between two lakes
if("lake" %in% colnames(marine_data) & "values" %in% colnames(marine_data)) {
  # Select two lakes for comparison
  lake_comparison <- marine_data %>%
    filter(lake %in% c("Michigan", "Superior")) %>%
    select(lake, values)
  
  # Perform t-test
  t_test_result <- t.test(values ~ lake, data = lake_comparison)
  
  # Display the results
  print(t_test_result)
  
  # Visualize the comparison
  ggplot(lake_comparison, aes(x = lake, y = values)) +
    geom_boxplot(fill = "lightblue") +
    labs(title = "Comparison of Fishing Yields Between Lakes",
         x = "Lake", y = "Yield Values") +
    theme_minimal()
} else {
  # If the columns don't match exactly, adapt to the actual structure
  # This is a fallback to ensure the code runs with the actual data
  print("Column names don't match expected structure. Adapting...")
  
  # Identify numeric columns for analysis
  numeric_cols <- sapply(marine_data, is.numeric)
  if(sum(numeric_cols) > 0) {
    numeric_col <- names(marine_data)[numeric_cols][1]
    
    # Identify a categorical column for grouping
    cat_cols <- sapply(marine_data, function(x) is.character(x) || is.factor(x))
    if(sum(cat_cols) > 0) {
      cat_col <- names(marine_data)[cat_cols][1]
      
      # Get the two most frequent categories
      top_categories <- names(sort(table(marine_data[[cat_col]]), decreasing = TRUE)[1:2])
      
      # Filter data for these categories
      comparison_data <- marine_data %>%
        filter(!!sym(cat_col) %in% top_categories) %>%
        select(!!sym(cat_col), !!sym(numeric_col))
      
      # Rename columns for easier formula creation
      names(comparison_data) <- c("category", "value")
      
      # Perform t-test
      t_test_result <- t.test(value ~ category, data = comparison_data)
      
      # Display the results
      print(t_test_result)
      
      # Visualize the comparison
      ggplot(comparison_data, aes(x = category, y = value)) +
        geom_boxplot(fill = "lightblue") +
        labs(title = paste("Comparison of", numeric_col, "Between Groups"),
             x = cat_col, y = numeric_col) +
        theme_minimal()
    }
  }
}
```

## Types of Errors in Hypothesis Testing

### Type I and Type II Errors

In hypothesis testing, two types of errors can occur:

1. **Type I Error**: Rejecting a true null hypothesis (false positive).
   - Probability = α (significance level)
   - Example: Concluding there's a difference in tree heights when there actually isn't.

2. **Type II Error**: Failing to reject a false null hypothesis (false negative).
   - Probability = β
   - Example: Failing to detect a real difference in tree heights.

### Statistical Power

Statistical power is the probability of correctly rejecting a false null hypothesis (1 - β). Factors affecting power include:

1. Sample size
2. Effect size
3. Significance level (α)
4. Variability in the data

```{r}
# Demonstrate power calculation for a t-test
library(pwr)

# Calculate power for our example
effect_size <- (28 - 25) / 5  # (mean difference) / standard deviation
power_result <- pwr.t.test(
  n = 30,                    # Sample size per group
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(power_result)

# Calculate required sample size for 80% power
sample_size_result <- pwr.t.test(
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  power = 0.8,               # Desired power
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(sample_size_result)
```

## One-Sample Tests

One-sample tests compare a sample mean to a known or hypothesized population value.

### One-Sample t-Test

The one-sample t-test is used when:
- The sample is approximately normally distributed
- The population standard deviation is unknown

## Two-Sample Tests

Two-sample tests compare means between two independent groups.

### Independent Samples t-Test

The independent samples t-test is used when:
- Both samples are approximately normally distributed
- The two samples are independent

## Non-Parametric Tests

Non-parametric tests are used when the assumptions of parametric tests (like normality) are violated.

### Mann-Whitney U Test (Wilcoxon Rank-Sum Test)

This is a non-parametric alternative to the independent samples t-test.

## Confidence Intervals

Confidence intervals provide a range of plausible values for a population parameter.

## Hypothesis Testing in Jamovi

Jamovi provides a user-friendly interface for conducting hypothesis tests:

1. **T-Tests**: For one-sample, independent samples, and paired samples t-tests
2. **Non-Parametric Tests**: For Mann-Whitney U and Wilcoxon signed-rank tests
3. **Descriptives**: For calculating confidence intervals

## Summary

In this chapter, we've covered the fundamental concepts and techniques of hypothesis testing in ecological and forestry research:

- Formulating null and alternative hypotheses
- Understanding p-values and significance levels
- Recognizing Type I and Type II errors
- Calculating and interpreting statistical power
- Conducting one-sample, two-sample, and paired tests
- Using non-parametric alternatives when necessary
- Calculating and interpreting confidence intervals

These statistical tools allow researchers to make informed inferences about populations based on sample data, helping to advance knowledge in ecology and forestry.

## Exercises

1. Formulate null and alternative hypotheses for an ecological research question of your choice.
2. Simulate data for two groups and perform an independent samples t-test.
3. Calculate the statistical power for your t-test and determine the sample size needed for 80% power.
4. Create a dataset where the normality assumption is violated and compare the results of a t-test and a Mann-Whitney U test.
5. Calculate and visualize a 95% confidence interval for a sample mean.
6. Perform the same hypothesis tests in Jamovi and compare the results with those obtained in R.

## Statistical Power

Statistical power is the probability of correctly rejecting the null hypothesis when it is false. It is influenced by:

1. Sample size
2. Effect size
3. Significance level (α)
4. Variability in the data

```{r}
# Demonstrate power calculation for a t-test
library(pwr)

# Calculate power for our example
effect_size <- (28 - 25) / 5  # (mean difference) / standard deviation
power_result <- pwr.t.test(
  n = 30,                    # Sample size per group
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(power_result)

# Calculate required sample size for 80% power
sample_size_result <- pwr.t.test(
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  power = 0.8,               # Desired power
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(sample_size_result)
