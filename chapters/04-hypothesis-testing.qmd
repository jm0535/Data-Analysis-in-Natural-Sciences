---
prefer-html: true
---

# Hypothesis Testing

## Introduction

Hypothesis testing is a fundamental statistical approach used to make inferences about populations based on sample data. In ecological and forestry research, hypothesis testing helps researchers determine whether observed patterns or differences are statistically significant or merely due to random chance.

```{r setup, include=FALSE}
# Load required packages for data analysis and visualization
library(tidyverse)
library(ggplot2)
library(knitr)
library(kableExtra)
library(magrittr)  # For the pipe operator %>%

# Set global knitr options
knitr::opts_chunk$set(
  echo = TRUE,        # Display code chunks
  warning = FALSE,    # Suppress warnings
  message = FALSE,    # Suppress messages
  fig.width = 8,      # Default figure width
  fig.height = 5,     # Default figure height
  fig.align = "center" # Center figures
)
```

## The Logic of Hypothesis Testing

### Null and Alternative Hypotheses

The foundation of hypothesis testing involves two competing hypotheses:

1. **Null Hypothesis (H₀)**: This is the default position that assumes no effect, no difference, or no relationship exists. For example, "There is no difference in tree height between two forest types."

2. **Alternative Hypothesis (H₁ or Hₐ)**: This is the hypothesis that the researcher typically wants to provide evidence for. For example, "There is a significant difference in tree height between two forest types."

### Example in Ecological Research

Let's consider a specific example from forestry research:

- **Research Question**: Is there a difference in the average height of oak trees between Site A and Site B?
- **Null Hypothesis (H₀)**: There is no difference in the average height of oak trees between Site A and Site B.
- **Alternative Hypothesis (H₁)**: There is a significant difference in the average height of oak trees between Site A and Site B.

## Understanding P-values and Significance Levels

### The P-value

The p-value is the probability of obtaining results at least as extreme as those observed, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis.

### Significance Level (Alpha)

The significance level, often denoted as α (alpha), represents the threshold for statistical significance. In most research, it is set at 0.05 (5%). This value signifies the maximum acceptable probability of making a Type I error — wrongly rejecting the null hypothesis when it is true.

## Example: Two-Sample t-test

```{r}
# Simulate tree height data for two sites
set.seed(123)
site_A <- rnorm(30, mean = 25, sd = 5)  # 30 trees with mean height 25m
site_B <- rnorm(30, mean = 28, sd = 5)  # 30 trees with mean height 28m

# Create a data frame
tree_data <- data.frame(
  height = c(site_A, site_B),
  site = factor(rep(c("A", "B"), each = 30))
)

# Visualize the data
library(ggplot2)
ggplot(tree_data, aes(x = site, y = height, fill = site)) +
  geom_boxplot() +
  labs(title = "Tree Heights by Site",
       x = "Site",
       y = "Height (m)") +
  theme_minimal()

# Perform a t-test
t_test_result <- t.test(height ~ site, data = tree_data)
print(t_test_result)

# Interpret the result
alpha <- 0.05
if (t_test_result$p.value < alpha) {
  cat("With a p-value of", round(t_test_result$p.value, 4), 
      "we reject the null hypothesis.\n",
      "There is a statistically significant difference in tree heights between sites.")
} else {
  cat("With a p-value of", round(t_test_result$p.value, 4), 
      "we fail to reject the null hypothesis.\n",
      "There is not enough evidence to conclude a significant difference in tree heights.")
}

# Create a formatted table of the results
t_test_table <- data.frame(
  Statistic = c("t-value", "Degrees of Freedom", "p-value", "Mean Difference", "95% CI Lower", "95% CI Upper"),
  Value = c(
    round(t_test_result$statistic, 3),
    round(t_test_result$parameter, 1),
    format.pval(t_test_result$p.value, digits = 3),
    round(diff(t_test_result$estimate), 2),
    round(t_test_result$conf.int[1], 2),
    round(t_test_result$conf.int[2], 2)
  )
)

# Display the formatted table
knitr::kable(t_test_table, 
             caption = "Two-Sample t-Test Results: Tree Heights by Site",
             align = c("l", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")
```

## Example: Using Marine Dataset for Two-Sample t-test

Let's apply the t-test to analyze real data. We'll use our marine dataset to compare fishing yields between different regions:

```{r}
# Load necessary packages
library(tidyverse)

# Load the marine dataset
marine_data <- read_csv("../data/marine/ocean_data.csv")

# View the structure of the dataset
str(marine_data)

# Let's compare fishing yields between two lakes
if("lake" %in% colnames(marine_data) & "values" %in% colnames(marine_data)) {
  # Select two lakes for comparison
  lake_comparison <- marine_data %>%
    filter(lake %in% c("Michigan", "Superior")) %>%
    select(lake, values)
  
  # Perform t-test
  t_test_result <- t.test(values ~ lake, data = lake_comparison)
  
  # Display the results
  print(t_test_result)
  
  # Visualize the comparison
  ggplot(lake_comparison, aes(x = lake, y = values)) +
    geom_boxplot(fill = "lightblue") +
    labs(title = "Comparison of Fishing Yields Between Lakes",
         x = "Lake", y = "Yield Values") +
    theme_minimal()
} else {
  # If the columns don't match exactly, adapt to the actual structure
  # This is a fallback to ensure the code runs with the actual data
  print("Column names don't match expected structure. Adapting...")
  
  # Identify numeric columns for analysis
  numeric_cols <- sapply(marine_data, is.numeric)
  if(sum(numeric_cols) > 0) {
    numeric_col <- names(marine_data)[numeric_cols][1]
    
    # Identify a categorical column for grouping
    cat_cols <- sapply(marine_data, function(x) is.character(x) || is.factor(x))
    if(sum(cat_cols) > 0) {
      cat_col <- names(marine_data)[cat_cols][1]
      
      # Get the two most frequent categories
      top_categories <- names(sort(table(marine_data[[cat_col]]), decreasing = TRUE)[1:2])
      
      # Filter data for these categories
      comparison_data <- marine_data %>%
        filter(!!sym(cat_col) %in% top_categories) %>%
        select(!!sym(cat_col), !!sym(numeric_col))
      
      # Rename columns for easier formula creation
      names(comparison_data) <- c("category", "value")
      
      # Perform t-test
      t_test_result <- t.test(value ~ category, data = comparison_data)
      
      # Display the results
      print(t_test_result)
      
      # Visualize the comparison
      ggplot(comparison_data, aes(x = category, y = value)) +
        geom_boxplot(fill = "lightblue") +
        labs(title = paste("Comparison of", numeric_col, "Between Groups"),
             x = cat_col, y = numeric_col) +
        theme_minimal()
    }
  }
}
```

## Types of Errors in Hypothesis Testing

### Type I and Type II Errors

In hypothesis testing, two types of errors can occur:

1. **Type I Error**: Rejecting a true null hypothesis (false positive).
   - Probability = α (significance level)
   - Example: Concluding there's a difference in tree heights when there actually isn't.

2. **Type II Error**: Failing to reject a false null hypothesis (false negative).
   - Probability = β
   - Example: Failing to detect a real difference in tree heights.

### Statistical Power

Statistical power is the probability of correctly rejecting a false null hypothesis (1 - β). Factors affecting power include:

1. Sample size
2. Effect size
3. Significance level (α)
4. Variability in the data

```{r}
# Demonstrate power calculation for a t-test
library(pwr)

# Calculate power for our example
effect_size <- (28 - 25) / 5  # (mean difference) / standard deviation
power_result <- pwr.t.test(
  n = 30,                    # Sample size per group
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(power_result)

# Calculate required sample size for 80% power
sample_size_result <- pwr.t.test(
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  power = 0.8,               # Desired power
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(sample_size_result)
```

## One-Sample Tests

One-sample tests compare a sample mean to a known or hypothesized population value.

### One-Sample t-Test

The one-sample t-test is used when:
- The sample is approximately normally distributed
- The population standard deviation is unknown

```{r}
# Simulate tree diameter data
set.seed(456)
tree_diameters <- rnorm(25, mean = 32, sd = 5)  # 25 trees with mean diameter 32cm

# Known reference value (e.g., from previous studies)
reference_diameter <- 30  # cm

# Visualize the data
ggplot(data.frame(diameter = tree_diameters), aes(x = diameter)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "white") +
  geom_vline(xintercept = reference_diameter, color = "red", linetype = "dashed", size = 1) +
  labs(title = "Tree Diameters with Reference Value",
       x = "Diameter (cm)",
       y = "Frequency") +
  annotate("text", x = reference_diameter + 2, y = 5, 
           label = "Reference", color = "red") +
  theme_minimal()

# Perform a one-sample t-test
one_sample_result <- t.test(tree_diameters, mu = reference_diameter)

# Create a formatted table of the results
one_sample_table <- data.frame(
  Statistic = c("t-value", "Degrees of Freedom", "p-value", "Mean Difference", "95% CI Lower", "95% CI Upper"),
  Value = c(
    round(one_sample_result$statistic, 3),
    round(one_sample_result$parameter, 1),
    format.pval(one_sample_result$p.value, digits = 3),
    round(mean(tree_diameters) - reference_diameter, 2),
    round(one_sample_result$conf.int[1], 2),
    round(one_sample_result$conf.int[2], 2)
  )
)

# Display the formatted table
knitr::kable(one_sample_table, 
             caption = "One-Sample t-Test Results: Tree Diameters vs. Reference Value",
             align = c("l", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")
```

## Two-Sample Tests

Two-sample tests compare means between two independent groups.

### Independent Samples t-Test

The independent samples t-test is used when:
- Both samples are approximately normally distributed
- The two samples are independent

```{r}
# We already performed this test in our initial example
# Let's visualize it differently

# Create density plots
ggplot(tree_data, aes(x = height, fill = site)) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribution of Tree Heights by Site",
       x = "Height (m)",
       y = "Density") +
  theme_minimal()

# Add mean lines
ggplot(tree_data, aes(x = height, fill = site)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = mean(site_A), color = "red", linetype = "dashed") +
  geom_vline(xintercept = mean(site_B), color = "blue", linetype = "dashed") +
  labs(title = "Distribution of Tree Heights by Site",
       x = "Height (m)",
       y = "Density") +
  theme_minimal()

# Perform the t-test again for demonstration
t_test_result <- t.test(height ~ site, data = tree_data, var.equal = TRUE)

# Create a formatted table of the results
t_test_table <- data.frame(
  Statistic = c("t-value", "Degrees of Freedom", "p-value", "Mean Difference", "95% CI Lower", "95% CI Upper"),
  Value = c(
    round(t_test_result$statistic, 3),
    round(t_test_result$parameter, 1),
    format.pval(t_test_result$p.value, digits = 3),
    round(diff(t_test_result$estimate), 2),
    round(t_test_result$conf.int[1], 2),
    round(t_test_result$conf.int[2], 2)
  )
)

# Display the formatted table
knitr::kable(t_test_table, 
             caption = "Independent Samples t-Test Results: Tree Heights by Site",
             align = c("l", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")

# Create a summary statistics table
site_summary <- tree_data %>%
  group_by(site) %>%
  summarize(
    n = n(),
    Mean = round(mean(height), 2),
    SD = round(sd(height), 2),
    Min = round(min(height), 2),
    Max = round(max(height), 2)
  )

# Display the summary statistics table
knitr::kable(site_summary, 
             caption = "Summary Statistics: Tree Heights by Site",
             align = c("l", "c", "r", "r", "r", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")
```

### Paired Samples t-Test

The paired samples t-test is used when:
- Measurements are taken from the same subjects under different conditions
- The differences between pairs are approximately normally distributed

```{r}
# Simulate paired data (e.g., tree growth before and after treatment)
set.seed(789)
before_treatment <- rnorm(20, mean = 15, sd = 3)
after_treatment <- before_treatment + rnorm(20, mean = 2.5, sd = 1)  # Growth effect

# Create a data frame
growth_data <- data.frame(
  tree_id = 1:20,
  before = before_treatment,
  after = after_treatment,
  difference = after_treatment - before_treatment
)

# Visualize paired data
growth_long <- reshape2::melt(growth_data[, c("tree_id", "before", "after")], 
                             id.vars = "tree_id", 
                             variable.name = "time", 
                             value.name = "height")

ggplot(growth_long, aes(x = time, y = height, group = tree_id)) +
  geom_line(alpha = 0.3) +
  geom_point(aes(color = time), size = 3) +
  labs(title = "Tree Heights Before and After Treatment",
       x = "Time",
       y = "Height (m)") +
  theme_minimal()

# Perform a paired t-test
paired_result <- t.test(growth_data$after, growth_data$before, paired = TRUE)

# Create a formatted table of the results
paired_table <- data.frame(
  Statistic = c("t-value", "Degrees of Freedom", "p-value", "Mean Difference", "95% CI Lower", "95% CI Upper"),
  Value = c(
    round(paired_result$statistic, 3),
    round(paired_result$parameter, 1),
    format.pval(paired_result$p.value, digits = 3),
    round(mean(growth_data$difference), 2),
    round(paired_result$conf.int[1], 2),
    round(paired_result$conf.int[2], 2)
  )
)

# Display the formatted table
knitr::kable(paired_table, 
             caption = "Paired Samples t-Test Results: Tree Heights Before and After Treatment",
             align = c("l", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")

# Create a summary statistics table
growth_summary <- growth_data %>%
  summarize(
    `Mean Before` = round(mean(before), 2),
    `SD Before` = round(sd(before), 2),
    `Mean After` = round(mean(after), 2),
    `SD After` = round(sd(after), 2),
    `Mean Difference` = round(mean(difference), 2),
    `SD Difference` = round(sd(difference), 2)
  )

# Display the summary statistics table
knitr::kable(growth_summary, 
             caption = "Summary Statistics: Tree Heights Before and After Treatment",
             align = rep("r", 6),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")
```

## Non-Parametric Tests

Non-parametric tests are used when the assumptions of parametric tests (like normality) are violated.

### Mann-Whitney U Test (Wilcoxon Rank-Sum Test)

This is a non-parametric alternative to the independent samples t-test.

```{r}
# Simulate non-normal data (e.g., species counts in two habitats)
set.seed(101)
habitat_A <- rpois(25, lambda = 8)  # Poisson distribution for count data
habitat_B <- rpois(25, lambda = 12)

# Create a data frame
species_data <- data.frame(
  count = c(habitat_A, habitat_B),
  habitat = factor(rep(c("A", "B"), each = 25))
)

# Visualize the data
ggplot(species_data, aes(x = habitat, y = count, fill = habitat)) +
  geom_boxplot() +
  labs(title = "Species Counts by Habitat",
       x = "Habitat",
       y = "Count") +
  theme_minimal()

# Check for normality
shapiro_A <- shapiro.test(habitat_A)
shapiro_B <- shapiro.test(habitat_B)

# Create a table for normality test results
normality_table <- data.frame(
  Habitat = c("Habitat A", "Habitat B"),
  `W Statistic` = c(round(shapiro_A$statistic, 3), round(shapiro_B$statistic, 3)),
  `p-value` = c(format.pval(shapiro_A$p.value, digits = 3), format.pval(shapiro_B$p.value, digits = 3)),
  Interpretation = c(
    ifelse(shapiro_A$p.value < 0.05, "Non-normal distribution", "Normal distribution"),
    ifelse(shapiro_B$p.value < 0.05, "Non-normal distribution", "Normal distribution")
  )
)

# Display the normality test results
knitr::kable(normality_table, 
             caption = "Shapiro-Wilk Test for Normality",
             align = c("l", "c", "c", "l"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")

# Perform Mann-Whitney U test
wilcox_result <- wilcox.test(count ~ habitat, data = species_data)

# Create a formatted table of the results
wilcox_table <- data.frame(
  Statistic = c("W-value", "p-value"),
  Value = c(
    wilcox_result$statistic,
    format.pval(wilcox_result$p.value, digits = 3)
  )
)

# Display the formatted table
knitr::kable(wilcox_table, 
             caption = "Mann-Whitney U Test Results: Species Counts by Habitat",
             align = c("l", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")

# Create a summary statistics table
habitat_summary <- species_data %>%
  group_by(habitat) %>%
  summarize(
    n = n(),
    Median = median(count),
    Mean = round(mean(count), 2),
    SD = round(sd(count), 2),
    Min = min(count),
    Max = max(count)
  )

# Display the summary statistics table
knitr::kable(habitat_summary, 
             caption = "Summary Statistics: Species Counts by Habitat",
             align = c("l", "c", "c", "r", "r", "c", "c"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")
```

### Wilcoxon Signed-Rank Test

This is a non-parametric alternative to the paired samples t-test.

```{r}
# Simulate non-normal paired data
set.seed(202)
before_restoration <- rpois(20, lambda = 5)
after_restoration <- before_restoration + rpois(20, lambda = 3)

# Create a data frame
restoration_data <- data.frame(
  site_id = 1:20,
  before = before_restoration,
  after = after_restoration,
  difference = after_restoration - before_restoration
)

# Visualize paired data
restoration_long <- reshape2::melt(restoration_data[, c("site_id", "before", "after")], 
                                  id.vars = "site_id", 
                                  variable.name = "time", 
                                  value.name = "species_count")

ggplot(restoration_long, aes(x = time, y = species_count, group = site_id)) +
  geom_line(alpha = 0.3) +
  geom_point(aes(color = time), size = 3) +
  labs(title = "Species Counts Before and After Restoration",
       x = "Time",
       y = "Species Count") +
  theme_minimal()

# Perform Wilcoxon signed-rank test
wilcox_paired_result <- wilcox.test(restoration_data$after, restoration_data$before, paired = TRUE)

# Create a formatted table of the results
wilcox_paired_table <- data.frame(
  Statistic = c("V-value", "p-value"),
  Value = c(
    wilcox_paired_result$statistic,
    format.pval(wilcox_paired_result$p.value, digits = 3)
  )
)

# Display the formatted table
knitr::kable(wilcox_paired_table, 
             caption = "Wilcoxon Signed-Rank Test Results: Species Counts Before and After Restoration",
             align = c("l", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")

# Create a summary statistics table
restoration_summary <- restoration_data %>%
  summarize(
    `Median Before` = median(before),
    `Mean Before` = round(mean(before), 2),
    `Median After` = median(after),
    `Mean After` = round(mean(after), 2),
    `Median Difference` = median(difference),
    `Mean Difference` = round(mean(difference), 2)
  )

# Display the summary statistics table
knitr::kable(restoration_summary, 
             caption = "Summary Statistics: Species Counts Before and After Restoration",
             align = rep("r", 6),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")
```

## Confidence Intervals

Confidence intervals provide a range of plausible values for a population parameter.

```{r}
# Calculate 95% confidence interval for mean tree height in Site A
ci_result <- t.test(site_A)

# Create a formatted table for the confidence interval
ci_table <- data.frame(
  Statistic = c("Sample Mean", "Standard Error", "95% CI Lower", "95% CI Upper", "Degrees of Freedom"),
  Value = c(
    round(mean(site_A), 2),
    round(sd(site_A)/sqrt(length(site_A)), 3),
    round(ci_result$conf.int[1], 2),
    round(ci_result$conf.int[2], 2),
    ci_result$parameter
  )
)

# Display the formatted table
knitr::kable(ci_table, 
             caption = "95% Confidence Interval for Mean Tree Height in Site A",
             align = c("l", "r"),
             format = "html") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), 
                           full_width = FALSE,
                           position = "center")

# Visualize confidence interval
mean_height <- mean(site_A)
ci_lower <- ci_result$conf.int[1]
ci_upper <- ci_result$conf.int[2]

ggplot(data.frame(height = site_A), aes(x = height)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "white") +
  geom_vline(xintercept = mean_height, color = "red", size = 1) +
  geom_vline(xintercept = ci_lower, color = "blue", linetype = "dashed") +
  geom_vline(xintercept = ci_upper, color = "blue", linetype = "dashed") +
  annotate("rect", xmin = ci_lower, xmax = ci_upper, ymin = 0, ymax = Inf, 
           alpha = 0.2, fill = "lightblue") +
  labs(title = "Tree Heights in Site A with 95% Confidence Interval",
       x = "Height (m)",
       y = "Frequency") +
  annotate("text", x = mean_height, y = 5, 
           label = paste("Mean =", round(mean_height, 2)), 
           color = "red", vjust = -1) +
  annotate("text", x = mean(c(ci_lower, ci_upper)), y = 3, 
           label = paste("95% CI: [", round(ci_lower, 2), ", ", round(ci_upper, 2), "]", sep = ""), 
           color = "blue") +
  theme_minimal()
```

## Exercises

1. Formulate a hypothesis about a relationship between two variables in the forest inventory dataset.
2. Conduct an appropriate statistical test to evaluate your hypothesis.
3. Calculate the effect size for your test.
4. Interpret the results, including the p-value and effect size.
5. Create a visualization that effectively communicates your findings.

## Summary

In this chapter, we've covered the fundamental concepts and techniques of hypothesis testing in ecological and forestry research:

- Formulating null and alternative hypotheses
- Understanding p-values and significance levels
- Recognizing Type I and Type II errors
- Calculating and interpreting statistical power
- Conducting one-sample, two-sample, and paired tests
- Using non-parametric alternatives when necessary
- Calculating and interpreting confidence intervals

These statistical tools allow researchers to make informed inferences about populations based on sample data, helping to advance knowledge in ecology and forestry.

## Statistical Power

Statistical power is the probability of correctly rejecting the null hypothesis when it is false. It is influenced by:

1. Sample size
2. Effect size
3. Significance level (α)
4. Variability in the data

```{r}
# Demonstrate power calculation for a t-test
library(pwr)

# Calculate power for our example
effect_size <- (28 - 25) / 5  # (mean difference) / standard deviation
power_result <- pwr.t.test(
  n = 30,                    # Sample size per group
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(power_result)

# Calculate required sample size for 80% power
sample_size_result <- pwr.t.test(
  d = effect_size,           # Cohen's d effect size
  sig.level = 0.05,          # Significance level
  power = 0.8,               # Desired power
  type = "two.sample",       # Two-sample t-test
  alternative = "two.sided"  # Two-sided alternative
)

print(sample_size_result)
